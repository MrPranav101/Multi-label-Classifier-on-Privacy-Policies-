from nltk.tokenize import word_tokenize


def tokenizer(doc):
    return word_tokenize(doc)

